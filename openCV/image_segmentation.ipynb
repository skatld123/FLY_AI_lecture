{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar_8U9_FdggY"
      },
      "outputs": [],
      "source": [
        "# 데이터 처리 및 분석을 위한 기본 라이브러리\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 시각화 도구\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 이미지 처리 관련 라이브러리\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "\n",
        "# 진행 상태를 추적하는 데 도움이 되는 라이브러리\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 딥러닝 모델링을 위한 TensorFlow 및 관련 콜백\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc9Nv6Ze3I-n"
      },
      "outputs": [],
      "source": [
        "# 다운로드가 안 될 경우 아래 명령어의 주석을 해제하고 실행한 후 다시 시도해보세요.\n",
        "# !pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjWyI6NjcDSP"
      },
      "outputs": [],
      "source": [
        "!gdown 12SmqZSWY8IGyPvCgdgpR7SXUQzSunCDE\n",
        "!unzip cityscapes.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty-9vqf-SuRM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def get_image_paths(directory):\n",
        "    return glob(os.path.join(directory, '*.jpg'))\n",
        "\n",
        "train_dir = 'cityscapes/train/'\n",
        "val_dir = 'cityscapes/val/'\n",
        "\n",
        "train_image_paths = get_image_paths(train_dir)\n",
        "val_image_paths = get_image_paths(val_dir)\n",
        "\n",
        "print(f\"Number of training images: {len(train_image_paths)}\")\n",
        "print(f\"Number of validation images: {len(val_image_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zbbn-EyD_Eu"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "Label = namedtuple( 'Label' , ['name', 'id' ,'trainId','category','categoryId','hasInstances','ignoreInEval','color'] )\n",
        "\n",
        "labels=[\n",
        "Label('unlabeled',0,255,'void',0,False,True,(0,0,0)),\n",
        "Label('egovehicle',1,255,'void',0,False,True,(0,0,0)),\n",
        "Label('rectificationborder',2,255,'void',0,False,True,(0,0,0)),\n",
        "Label('outofroi',3,255,'void',0,False,True,(0,0,0)),\n",
        "Label('static',4,255,'void',0,False,True,(0,0,0)),\n",
        "Label('dynamic',5,255,'void',0,False,True,(111,74,0)),\n",
        "Label('ground',6,255,'void',0,False,True,(81,0,81)),\n",
        "Label('road',7,0,'ground',1,False,False,(128,64,128)),\n",
        "Label('sidewalk',8,1,'ground',1,False,False,(244,35,232)),\n",
        "Label('parking',9,255,'ground',1,False,True,(250,170,160)),\n",
        "Label('railtrack',10,255,'ground',1,False,True,(230,150,140)),\n",
        "Label('building',11,2,'construction',2,False,False,(70,70,70)),\n",
        "Label('wall',12,3,'construction',2,False,False,(102,102,156)),\n",
        "Label('fence',13,4,'construction',2,False,False,(190,153,153)),\n",
        "Label('guardrail',14,255,'construction',2,False,True,(180,165,180)),\n",
        "Label('bridge',15,255,'construction',2,False,True,(150,100,100)),\n",
        "Label('tunnel',16,255,'construction',2,False,True,(150,120,90)),\n",
        "Label('pole',17,5,'object',3,False,False,(153,153,153)),\n",
        "Label('polegroup',18,255,'object',3,False,True,(153,153,153)),\n",
        "Label('trafficlight',19,6,'object',3,False,False,(250,170,30)),\n",
        "Label('trafficsign',20,7,'object',3,False,False,(220,220,0)),\n",
        "Label('vegetation',21,8,'nature',4,False,False,(107,142,35)),\n",
        "Label('terrain',22,9,'nature',4,False,False,(152,251,152)),\n",
        "Label('sky',23,10,'sky',5,False,False,(70,130,180)),\n",
        "Label('person',24,11,'human',6,True,False,(220,20,60)),\n",
        "Label('rider',25,12,'human',6,True,False,(255,0,0)),\n",
        "Label('car',26,13,'vehicle',7,True,False,(0,0,142)),\n",
        "Label('truck',27,14,'vehicle',7,True,False,(0,0,70)),\n",
        "Label('bus',28,15,'vehicle',7,True,False,(0,60,100)),\n",
        "Label('caravan',29,255,'vehicle',7,True,True,(0,0,90)),\n",
        "Label('trailer',30,255,'vehicle',7,True,True,(0,0,110)),\n",
        "Label('train',31,16,'vehicle',7,True,False,(0,80,100)),\n",
        "Label('motorcycle',32,17,'vehicle',7,True,False,(0,0,230)),\n",
        "Label('bicycle',33,18,'vehicle',7,True,False,(119,11,32)),\n",
        "Label('licenseplate',34,19,'vehicle',7,False,True,(0,0,142)),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGvtTf-0IkXq"
      },
      "outputs": [],
      "source": [
        "N_FILTERS = 64\n",
        "KERNEL_SIZE = 3\n",
        "N_CLASSES = len(labels)\n",
        "IMAGE_SIZE = 128\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "MODEL_CHECKPOINT_FILEPATH = './cityscapes-unet.ckpt'\n",
        "\n",
        "id2color = { label.id : np.asarray(label.color) for label in labels } #id에 따른 컬러"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ysUfHbSIrU2"
      },
      "outputs": [],
      "source": [
        "def image_mask_split(filename, image_size):\n",
        "    image_mask = Image.open(filename)\n",
        "    image, mask = image_mask.crop([0, 0, 256, 256]), image_mask.crop([256, 0, 512, 256])\n",
        "    image = image.resize((image_size, image_size))\n",
        "    mask = mask.resize((image_size, image_size))\n",
        "    image = np.array(image) / 255\n",
        "    mask = np.array(mask)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "def find_closest_labels_vectorized(mask, mapping):\n",
        "    closest_distance = np.full([mask.shape[0], mask.shape[1]], 10000)\n",
        "    closest_category = np.full([mask.shape[0], mask.shape[1]], None)\n",
        "    for id, color in mapping.items():\n",
        "        dist = np.sqrt(np.linalg.norm(mask - color.reshape([1,1,-1]), axis=-1))\n",
        "        is_closer = closest_distance > dist\n",
        "        closest_distance = np.where(is_closer, dist, closest_distance)\n",
        "        closest_category = np.where(is_closer, id, closest_category)\n",
        "    return closest_category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Ktb1MOQJxZH"
      },
      "outputs": [],
      "source": [
        "train_images = []\n",
        "train_masks = []\n",
        "train_masks_enc = []\n",
        "val_images = []\n",
        "val_masks = []\n",
        "val_masks_enc = []\n",
        "\n",
        "train_lists = glob(f'{train_dir}*.jpg')\n",
        "val_lists = glob(f'{val_dir}*.jpg')\n",
        "print(len(train_lists), len(val_lists))\n",
        "\n",
        "for train_file in tqdm(train_lists, desc = 'Building Training Dataset: '):\n",
        "    image, mask = image_mask_split(train_file, IMAGE_SIZE)\n",
        "    train_images.append(image)\n",
        "    train_masks.append(mask)\n",
        "    train_masks_enc.append(find_closest_labels_vectorized(mask, id2color))\n",
        "\n",
        "for val_file in tqdm(val_lists, desc = 'Building Validation Dataset: '):\n",
        "    image, mask = image_mask_split(val_file, IMAGE_SIZE)\n",
        "    val_images.append(image)\n",
        "    val_masks.append(mask)\n",
        "    val_masks_enc.append(find_closest_labels_vectorized(mask, id2color))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WggCWuoCJyqA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[20, 14])\n",
        "\n",
        "\n",
        "for i in range(2):\n",
        "    img = train_images[i]\n",
        "    msk = train_masks[i]\n",
        "    enc = train_masks_enc[i]\n",
        "\n",
        "    tmp = np.zeros([enc.shape[0], enc.shape[1], 3])\n",
        "    for row in range(enc.shape[0]):\n",
        "        for col in range(enc.shape[1]):\n",
        "            tmp[row, col, :] = id2color[enc[row, col]]\n",
        "            tmp = tmp.astype('uint8')\n",
        "\n",
        "    plt.subplot(2, 3, i*3 + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.gca().set_title('Sample image {}'.format(str(i+1)))\n",
        "\n",
        "    plt.subplot(2, 3, i*3 + 2)\n",
        "    plt.imshow(msk)\n",
        "    plt.axis('off')\n",
        "    plt.gca().set_title('Sample mask {}'.format(str(i+1)))\n",
        "\n",
        "    plt.subplot(2, 3, i*3 + 3)\n",
        "    plt.imshow(tmp)\n",
        "    plt.axis('off')\n",
        "    plt.gca().set_title('Encoded sameple mask {}'.format(str(i+1)))\n",
        "\n",
        "plt.subplots_adjust(wspace=0, hspace=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pYQcx5oTlg8C"
      },
      "outputs": [],
      "source": [
        "# 이미지와 마스크를 numpy 배열로 변환하고 데이터 타입을 'float32'로 설정\n",
        "train_images = np.stack(train_images).astype('float32')\n",
        "train_masks_enc = np.stack(train_masks_enc).astype('float32')\n",
        "\n",
        "val_images = np.stack(val_images).astype('float32')\n",
        "val_masks_enc = np.stack(val_masks_enc).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8SHBZ694mKtA"
      },
      "outputs": [],
      "source": [
        "def conv2d_block(input_tensor, n_filters, kernel_size=3):  # conv2d_block 함수를 정의합니다.\n",
        "    x = input_tensor  # 입력 텐서를 변수 x에 저장합니다.\n",
        "    for i in range(2):  # 2개의 Conv2D 레이어를 추가하기 위해 반복합니다.\n",
        "        # Conv2D 레이어를 추가합니다. He 초기화와 ReLU 활성화를 사용하고, 패딩은 'same'으로 설정합니다.\n",
        "        x = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=kernel_size,\n",
        "                                   kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
        "    return x  # 마지막 레이어의 출력을 반환합니다.\n",
        "\n",
        "\n",
        "def encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=0.3):  # encoder_block 함수를 정의합니다.\n",
        "    f = conv2d_block(inputs, n_filters)  # 입력에 대해 conv2d_block을 적용하여 특징 맵을 생성합니다.\n",
        "    p = tf.keras.layers.MaxPooling2D(pool_size=pool_size)(f)  # MaxPooling2D 레이어를 적용하여 다운샘플링합니다.\n",
        "    p = tf.keras.layers.Dropout(dropout)(p)  # 드롭아웃을 적용합니다.\n",
        "\n",
        "    return f, p  # 특징 맵과 풀링된 출력을 반환합니다.\n",
        "\n",
        "\n",
        "def encoder(inputs):  # encoder 함수를 정의합니다.\n",
        "    f1, p1 = encoder_block(inputs, n_filters=64)  # 첫 번째 인코더 블록을 추가합니다.\n",
        "    f2, p2 = encoder_block(p1, n_filters=128)  # 두 번째 인코더 블록을 추가합니다.\n",
        "    f3, p3 = encoder_block(p2, n_filters=256)  # 세 번째 인코더 블록을 추가합니다.\n",
        "    f4, p4 = encoder_block(p3, n_filters=512)  # 네 번째 인코더 블록을 추가합니다.\n",
        "\n",
        "    return p4, (f1, f2, f3, f4)  # 마지막 풀링된 출력과 모든 특징 맵을 반환합니다.\n",
        "\n",
        "def bottleneck(inputs):  # bottleneck 함수를 정의합니다.\n",
        "    bottle_neck = conv2d_block(inputs, n_filters=1024)  # conv2d_block을 적용하여 병목 레이어를 생성합니다.\n",
        "    return bottle_neck  # 병목 레이어의 출력을 반환합니다.\n",
        "\n",
        "# Decoder\n",
        "def decoder_block(inputs, conv_output, n_filters=64, kernel_size=3, strides=3, dropout=0.3):  # decoder_block 함수를 정의합니다.\n",
        "    u = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size, strides, padding='same')(inputs)  # Conv2DTranspose 레이어를 적용하여 업샘플링합니다.\n",
        "    c = tf.keras.layers.concatenate([u, conv_output])  # 업샘플링된 출력과 인코더의 출력을 연결합니다.\n",
        "    c = tf.keras.layers.Dropout(dropout)(c)  # 드롭아웃을 적용합니다.\n",
        "    c = conv2d_block(c, n_filters)  # conv2d_block을 적용하여 특징 맵을 생성합니다.\n",
        "\n",
        "    return c  # 마지막 레이어의 출력을 반환합니다.\n",
        "\n",
        "def decoder(inputs, convs, output_channels):  # decoder 함수를 정의합니다.\n",
        "    f1, f2, f3, f4 = convs  # 인코더에서 전달된 특징 맵들을 분해합니다.\n",
        "\n",
        "    c6 = decoder_block(inputs, f4, n_filters=512, kernel_size=3, strides=2)  # 첫 번째 디코더 블록을 추가합니다.\n",
        "    c7 = decoder_block(c6, f3, n_filters=256, kernel_size=3, strides=2)  # 두 번째 디코더 블록을 추가합니다.\n",
        "    c8 = decoder_block(c7, f2, n_filters=128, kernel_size=3, strides=2)  # 세 번째 디코더 블록을 추가합니다.\n",
        "    c9 = decoder_block(c8, f1, n_filters=64, kernel_size=3, strides=2)  # 네 번째 디코더 블록을 추가합니다.\n",
        "    outputs = tf.keras.layers.Conv2D(output_channels, 1, activation='softmax')(c9)  # 마지막 Conv2D 레이어를 추가하여 출력 채널 수를 맞추고 softmax 활성화를 적용합니다.\n",
        "\n",
        "    return outputs  # 최종 출력을 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IlAFsahrnGfl"
      },
      "outputs": [],
      "source": [
        "OUTPUT_CHANNELS = N_CLASSES\n",
        "\n",
        "def UNet():\n",
        "    inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
        "\n",
        "    encoder_output, convs = encoder(inputs)\n",
        "    bottle_neck = bottleneck(encoder_output)\n",
        "    outputs = decoder(bottle_neck, convs, OUTPUT_CHANNELS)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = UNet()\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, show_shapes = True,dpi=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JCnvdOUasFu7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics = ['accuracy'])\n",
        "model_checkpoint = ModelCheckpoint(MODEL_CHECKPOINT_FILEPATH, monitor='val_loss', save_best_only=True, save_weights_only=True,verbose=1, mode = 'min')\n",
        "history = model.fit(x = train_images,\n",
        "                    y = train_masks_enc,\n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    epochs = EPOCHS,\n",
        "                    validation_data = (val_images, val_masks_enc),\n",
        "                    callbacks = [model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wlx-8D69wHeo"
      },
      "outputs": [],
      "source": [
        "# 모델 시각화\n",
        "plt.plot(history.history['loss'], label='Train loss')\n",
        "plt.plot(history.history['val_loss'], label = 'Validation loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jj3Nf4dw0hXB"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[15, 20])\n",
        "\n",
        "for i in range(4):\n",
        "    img = val_images[i] # i번째 이미지를 가져옵니다.\n",
        "    enc = val_masks_enc[i] # i번째 이미지에 대한 정답 마스크를 가져옵니다.\n",
        "\n",
        "    # 이미지를 모델에 전달하여 예측을 생성합니다.\n",
        "    # reshape 함수를 사용하여 입력을 모델이 예상하는 형태로 만듭니다.\n",
        "    pred = model.predict(img.reshape([1] + [IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
        "    # 예측 결과는 각 클래스에 대한 확률을 포함하므로 argmax 함수를 사용하여 가장 높은 확률을 가진 클래스를 선택합니다.\n",
        "    pred = np.squeeze(np.argmax(pred, axis=-1))\n",
        "\n",
        "    # 마스크와 예측을 시각화할 빈 이미지를 생성합니다.\n",
        "    tmp1 = np.zeros([enc.shape[0], enc.shape[1], 3])\n",
        "    tmp2 = np.zeros([enc.shape[0], enc.shape[1], 3])\n",
        "\n",
        "    # 각 픽셀에 대해 반복합니다.\n",
        "    for row in range(enc.shape[0]):\n",
        "        for col in range(enc.shape[1]):\n",
        "            # 각 픽셀의 레이블에 해당하는 색을 id2color 사전에서 찾아서 임시 이미지에 할당합니다.\n",
        "            tmp1[row, col, :] = id2color[enc[row, col]]\n",
        "            tmp1 = tmp1.astype('uint8') # uint8 형식으로 변환합니다.\n",
        "\n",
        "            tmp2[row, col, :] = id2color[pred[row, col]]\n",
        "            tmp2 = tmp2.astype('uint8') # uint8 형식으로 변환합니다.\n",
        "\n",
        "    # 원본 이미지, 마스크, 예측 결과를 그림에 그립니다.\n",
        "    plt.subplot(4, 3, i*3 + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.gca().set_title('Image {}'.format(str(i+1)))\n",
        "\n",
        "    plt.subplot(4, 3, i*3 + 2)\n",
        "    plt.imshow(tmp1)\n",
        "    plt.axis('off')\n",
        "    plt.gca().set_title('Encoded Mask {}'.format(str(i+1)))\n",
        "\n",
        "    plt.subplot(4, 3, i*3 + 3)\n",
        "    plt.imshow(tmp2)\n",
        "    plt.axis('off')\n",
        "    plt.gca().set_title('Model Prediction {}'.format(str(i+1)))\n",
        "\n",
        "# subplot 사이의 간격을 조정합니다.\n",
        "plt.subplots_adjust(wspace=0, hspace=0.1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}