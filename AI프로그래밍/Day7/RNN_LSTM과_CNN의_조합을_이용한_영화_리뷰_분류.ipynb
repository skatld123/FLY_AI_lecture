{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vQYiQh4906oo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터로드"
      ],
      "metadata": {
        "id": "OdF2kmKtQEnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "train_dataset = urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "test_dataset = urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
      ],
      "metadata": {
        "id": "uOwzC-4EQGxC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (X_train, y_train), (X_test, y_test) = imdb.load_data(path='ratings_train.txt', num_words=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4esrwXZbRN24",
        "outputId": "744683c4-0259-4edb-deb8-049bf3f749da"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_table('ratings_train.txt')\n",
        "test_df = pd.read_table('ratings_test.txt')\n",
        "\n",
        "train_df.drop(columns=['id'], inplace=True)\n",
        "test_df.drop(columns=['id'], inplace=True)\n",
        "train_df.dropna(inplace=True)\n",
        "test_df.dropna(inplace=True)\n",
        "\n",
        "x_train = train_df['document']\n",
        "y_train = train_df['label']\n",
        "x_test = test_df['document']\n",
        "y_test = test_df['label']\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n",
        "print(train_df.isnull().sum())\n",
        "print(test_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE7j6fKVQpHD",
        "outputId": "201a67f3-f6b8-4707-8e2a-6a5cb5d9adbe"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            document  label\n",
            "0                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
            "1                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
            "2                                  너무재밓었다그래서보는것을추천한다      0\n",
            "3                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
            "4  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
            "                                            document  label\n",
            "0                                                굳 ㅋ      1\n",
            "1                               GDNTOPCLASSINTHECLUB      0\n",
            "2             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
            "3                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
            "4  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
            "document    0\n",
            "label       0\n",
            "dtype: int64\n",
            "document    0\n",
            "label       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.head())\n",
        "print(y_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQUaXOjwVI8y",
        "outputId": "4538514c-edba-4eb9-d7ad-029e645e5743"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                  굳 ㅋ\n",
            "1                                 GDNTOPCLASSINTHECLUB\n",
            "2               뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
            "3                     지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
            "4    3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
            "Name: document, dtype: object\n",
            "0    1\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 인코딩"
      ],
      "metadata": {
        "id": "f4cy-P6rSSaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍',\n",
        "             '과','도','를','으로','자','에','와','한','하다',\n",
        "             '!', '?', ',', '.', '..', '...', '....', 'ㅋ']"
      ],
      "metadata": {
        "id": "dft8f0BgSUuO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# 정규 표현식을 이용하여 한글 이외의 문자 제거\n",
        "train_df['document'] = train_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "test_df['document'] = test_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "\n",
        "# 불용어 제거\n",
        "train_df['document'] = train_df['document'].apply(lambda x: [word for word in x.split() if word not in stopwords])\n",
        "test_df['document'] = test_df['document'].apply(lambda x: [word for word in x.split() if word not in stopwords])\n",
        "\n",
        "# 단어를 구분하고 정수형으로 인코딩\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_df['document'])\n",
        "train_sequences = tokenizer.texts_to_sequences(train_df['document'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_df['document'])\n",
        "\n",
        "# 문장 길이를 동일하게 맞추기 위해 패딩\n",
        "train_padded = sequence.pad_sequences(train_sequences, maxlen=100)\n",
        "test_padded = sequence.pad_sequences(test_sequences, maxlen=100)\n"
      ],
      "metadata": {
        "id": "1x4LFHa5S5Ub"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_padded.shape)\n",
        "print(test_padded.shape)\n",
        "print(type(train_padded))"
      ],
      "metadata": {
        "id": "YJlTlR_d1qti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5def055-ff46-4bee-e4e0-6faded996949"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(149995, 100)\n",
            "(49997, 100)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# LSTM만 만들어보고, 그 이후에 레이어 추가해서 해보고, 긍정/부정으로 나누어보던가\n",
        "#모델 구조 설정\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, 500))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Conv1D(64, 5, padding='valid', activation='relu', strides=1))\n",
        "# model.add(MaxPooling1D(pool_size=4))\n",
        "\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "model.add(layers.SimpleRNN(128))\n",
        "\n",
        "# model.add(LSTM(55))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "metadata": {
        "id": "J4lYqVsa17f1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXnR-Poh2m6v",
        "outputId": "60779c56-2323-4fe7-a611-3d13ba7c33cc"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 500)         2500000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, None, 256)         582144    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 128)               49280     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3131553 (11.95 MB)\n",
            "Trainable params: 3131553 (11.95 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 실행 옵션\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QbrVC3_n3IMw"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 조기 중단 설정\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "k-J_3Xlb3-G4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 실행\n",
        "history = model.fit(train_padded, y_train, batch_size=40, epochs=100,\n",
        "                    validation_split=0.25,\n",
        "                    callbacks=[early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcMkbe8r4DuD",
        "outputId": "3cfbe777-d6cb-465b-9e40-c180369f7495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2813/2813 [==============================] - 215s 75ms/step - loss: 0.5011 - accuracy: 0.7278 - val_loss: 0.4685 - val_accuracy: 0.7516\n",
            "Epoch 2/100\n",
            "2813/2813 [==============================] - 195s 69ms/step - loss: 0.4445 - accuracy: 0.7654 - val_loss: 0.4685 - val_accuracy: 0.7537\n",
            "Epoch 3/100\n",
            "2813/2813 [==============================] - 192s 68ms/step - loss: 0.4205 - accuracy: 0.7774 - val_loss: 0.4680 - val_accuracy: 0.7563\n",
            "Epoch 4/100\n",
            "2813/2813 [==============================] - 192s 68ms/step - loss: 0.3946 - accuracy: 0.7893 - val_loss: 0.4946 - val_accuracy: 0.7534\n",
            "Epoch 5/100\n",
            "2371/2813 [========================>.....] - ETA: 29s - loss: 0.3660 - accuracy: 0.8034"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과 시각화"
      ],
      "metadata": {
        "id": "XbfqeuO2KDQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "  plt.figure(figsize=(16,8))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(hist['epoch'], hist['loss'], label='Train Loss')\n",
        "  plt.plot(hist['epoch'], hist['val_loss'], label = 'Val Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.plot(hist['epoch'], hist['accuracy'], label='Train Accuracy')\n",
        "  plt.plot(hist['epoch'], hist['val_accuracy'], label = 'Val Accuracy')\n",
        "  plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1gH3QR0wK62a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "dQ_lnOwlKDU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_padded, y_test)"
      ],
      "metadata": {
        "id": "gDJD-9lMobxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(test_padded)"
      ],
      "metadata": {
        "id": "laSu-Z3pXzRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text, prediction, gt in zip(x_test[:10], pred[:10], y_test[:10]):\n",
        "  print(f'{text} : \\n모델예측결과={prediction}, GT={gt}')"
      ],
      "metadata": {
        "id": "B7WNgopjYJcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4sGidq9bZDqV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}