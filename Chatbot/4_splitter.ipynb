{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcPkKH1oB3h-",
        "outputId": "e87b2276-4522-4563-c32b-d6fd5bc0c2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.2.28-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.97-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m745.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.28-py3-none-any.whl (379 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.97-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.12 langchain-community-0.2.11 langchain-core-0.2.28 langchain-text-splitters-0.2.2 langsmith-0.1.97 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.6 tenacity-8.5.0 typing-inspect-0.9.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-core\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/generative ai.txt') as f:\n",
        "  text_gen_ai = f.read()"
      ],
      "metadata": {
        "id": "x7fmXa1cCW9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        ")"
      ],
      "metadata": {
        "id": "A1onTZypC747"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.split_text(text_gen_ai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da-XjzVJFk0Z",
        "outputId": "2e7ced18-2fd0-4e15-c1ad-8fa0aa9dacd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1003, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2239, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5023, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3461, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1266, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1143, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2523, which is longer than the specified 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[0])\n",
        "print('-' * 100)\n",
        "print(texts[1])\n",
        "print('-' * 100)\n",
        "print(texts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvdhAHlfFw7T",
        "outputId": "3227f1bd-9298-4721-82ca-26f69940d187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is generative AI?\n",
            "Generative AI can learn from existing artifacts to generate new, realistic artifacts (at scale) that reflect the characteristics of the training data but don’t repeat it. It can produce a variety of novel content, such as images, video, music, speech, text, software code and product designs.  \n",
            "Generative AI uses a number of techniques that continue to evolve. Foremost are AI foundation models, which are trained on a broad set of unlabeled data that can be used for different tasks, with additional fine-tuning. Complex math and enormous computing power are required to create these trained models, but they are, in essence, prediction algorithms. \n",
            "Today, generative AI most commonly creates content in response to natural language requests — it doesn’t require knowledge of or entering code — but the enterprise use cases are numerous and include innovations in drug and chip design and material science development. (Also see “What are some practical uses of generative AI?”)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "What’s behind the sudden hype about generative AI?\n",
            "Gartner has tracked generative AI on its Hype Cycle™ for Artificial Intelligence since 2020 (also, generative AI was among our Top Strategic Technology Trends for 2022), and the technology has moved from the Innovation Trigger phase to the Peak of Inflated Expectations. But generative AI only hit mainstream headlines in late 2022 with the launch of ChatGPT, a chatbot capable of very human-seeming interactions.\n",
            "ChatGPT, launched by OpenAI, became wildly popular overnight and galvanized public attention. (OpenAI’s DALL·E 2 tool similarly generates images from text in a related generative AI innovation.)\n",
            "Gartner sees generative AI becoming a general-purpose technology with an impact similar to that of the steam engine, electricity and the internet. The hype will subside as the reality of implementation sets in, but the impact of generative AI will grow as people and enterprises discover more innovative applications for the technology in daily work and life.\n",
            "FAQ on ChatGPT \n",
            "What are the benefits and applications of generative AI?\n",
            "Foundation models, including generative pretrained transformers (which drives ChatGPT), are among the AI architecture innovations that can be used to automate, augment humans or machines, and autonomously execute business and IT processes. \n",
            "The benefits of generative AI include faster product development, enhanced customer experience and improved employee productivity, but the specifics depend on the use case. End users should be realistic about the value they are looking to achieve, especially when using a service as is, which has major limitations. Generative AI creates artifacts that can be inaccurate or biased, making human validation essential and potentially limiting the time it saves workers. Gartner recommends connecting use cases to KPIs to ensure that any project either improves operational efficiency or creates net new revenue or better experiences.\n",
            "In a recent Gartner webinar poll of more than 2,500 executives, 38% indicated that customer experience and retention is the primary purpose of their generative AI investments. This was followed by revenue growth (26%), cost optimization (17%) and business continuity (7%).\n",
            "----------------------------------------------------------------------------------------------------\n",
            "What are the risks of generative AI?\n",
            "The risks associated with generative AI are significant and rapidly evolving. A wide array of threat actors have already used the technology to create “deep fakes” or copies of products, and generate artifacts to support increasingly complex scams.\n",
            "ChatGPT and other tools like it are trained on large amounts of publicly available data. They are not designed to be compliant with General Data Protection Regulation (GDPR) and other copyright laws, so it’s imperative to pay close attention to your enterprises’ uses of the platforms. \n",
            "Oversight risks to monitor include:\n",
            "\t•\tLack of transparency. Generative AI and ChatGPT models are unpredictable, and not even the companies behind them always understand everything about how they work.\n",
            "\t•\tAccuracy. Generative AI systems sometimes produce inaccurate and fabricated answers. Assess all outputs for accuracy, appropriateness and actual usefulness before relying on or publicly distributing information. \n",
            "\t•\tBias. You need policies or controls in place to detect biased outputs and deal with them in a manner consistent with company policy and any relevant legal requirements.\n",
            "\t•\tIntellectual property (IP) and copyright. There are currently no verifiable data governance and protection assurances regarding confidential enterprise information. Users should assume that any data or queries they enter into the ChatGPT and its competitors will become public information, and we advise enterprises to put in place controls to avoid inadvertently exposing IP. \n",
            "\t•\tCybersecurity and fraud. Enterprises must prepare for malicious actors’ use of generative AI systems for cyber and fraud attacks, such as those that use deep fakes for social engineering of personnel, and ensure mitigating controls are put in place. Confer with your cyber-insurance provider to verify the degree to which your existing policy covers AI-related breaches.\n",
            "\t•\tSustainability. Generative AI uses significant amounts of electricity. Choose vendors that reduce power consumption and leverage high-quality renewable energy to mitigate the impact on your sustainability goals.\n",
            "Gartner also recommends considering the following questions:\n",
            "\t•\tWho defines responsible use of generative AI, especially as cultural norms evolve and social engineering approaches vary across geographies? Who ensures compliance? What are the consequences for irresponsible use? \n",
            "\t•\tIn the event something goes wrong, how can individuals take action?\n",
            "\t•\tHow do users give and remove consent (opt in or opt out)? What can be learned from the privacy debate?\n",
            "\t•\tWill using generative AI help or hurt trust in your organization — and institutions overall?\n",
            "\t•\tHow can we ensure that content creators and owners keep control of their IP and are compensated fairly? What should new economic models look like? \n",
            "\t•\tWho will ensure proper functioning throughout the entire life cycle, and how will they do so? Do boards need an AI ethics lead, for example?\n",
            "Finally, it’s important to continually monitor regulatory developments and litigation regarding generative AI. China and Singapore have already put in place new regulations regarding the use of generative AI, while Italy temporarily. The U.S., Canada, India, the U.K. and the EU are currently shaping their regulatory environments.\n",
            "Also see, “What are the best practices for using generative AI?” and “Should I craft a usage policy for generative AI?”\n",
            "GenAI Risks & Opportunities \n",
            "What are some practical uses of generative AI today?\n",
            "The field of generative AI will progress rapidly in both scientific discovery and technology commercialization, but use cases are emerging quickly in creative content, content improvement, synthetic data, generative engineering and generative design. \n",
            "In-use, high-level practical applications today include the following.\n",
            "\t•\tWritten content augmentation and creation: Producing a “draft” output of text in a desired style and length\n",
            "\t•\tQuestion answering and discovery: Enabling users to locate answers to input, based on data and prompt information\n",
            "\t•\tTone: Text manipulation, to soften language or professionalize text\n",
            "\t•\tSummarization: Offering shortened versions of conversations, articles, emails and webpages\n",
            "\t•\tSimplification: Breaking down titles, creating outlines and extracting key content\n",
            "\t•\tClassification of content for specific use cases: Sorting by sentiment, topic, etc.\n",
            "\t•\tChatbot performance improvement: Bettering “sentity” extraction, whole-conversation sentiment classification and generation of journey flows from general descriptions\n",
            "\t•\tSoftware coding: Code generation, translation, explanation and verification\n",
            "Emerging use cases with long-term impacts include:\n",
            "\t•\tCreating medical images that show the future development of a disease \n",
            "\t•\tSynthetic data helping augment scarce data, mitigate bias, preserve data privacy and simulate future scenarios\n",
            "\t•\tApplications proactively suggesting additional actions to users and providing them with information\n",
            "\t•\tLegacy code modernization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_list = []\n",
        "for i in range(len(texts)):\n",
        "  char_list.append(len(texts[i]))\n",
        "\n",
        "print(char_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp0OWkckGVCG",
        "outputId": "e26ce8e1-0318-45c4-e998-6a6b77f2cd09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1003, 2238, 5022, 3460, 1265, 995, 1142, 2523, 3101]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/DJI_Osmo_Pocket_3_User_Manual_v1.0_en.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "J0DU87uNGsG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aGBXB8oHpm-",
        "outputId": "5f46021a-e3db-40a0-e604-b52a20f3cab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pages[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKOK2OKpHvfN",
        "outputId": "15cdd275-dea5-49ea-b836-60880af582e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 © 0000 大疆创新 版权所有 Searching for Keywords\n",
            "Search for keywords such as “battery” and “install” to find a topic. If you are using Adobe \n",
            "Acrobat Reader to read this document, press Ctrl+F on Windows or Command+F on Mac \n",
            "to begin a search.\n",
            " Navigating to a Topic\n",
            "View a complete list of topics in the table of contents. Click on a topic to navigate to that \n",
            "section.\n",
            " Printing this Document\n",
            "This document supports high resolution printing.This document is copyrighted by DJI with all rights reserved. Unless otherwise authorized by \n",
            "DJI, you are not eligible to use or allow others to use the document or any part of the document \n",
            "by reproducing, transferring or selling the document. Users should only refer to this document \n",
            "and the content thereof as instructions to operate DJI UAV. The document should not be used \n",
            "for other purposes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(\n",
        "    #separator = \"\\n\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "wX5EpH_9H2xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y1vAloyIJ11",
        "outputId": "c44f012e-c777-42d2-f9f3-3f7e45288b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 © 0000 大疆创新 版权所有 Searching for Keywords\n",
            "Search for keywords such as “battery” and “install” to find a topic. If you are using Adobe \n",
            "Acrobat Reader to read this document, press Ctrl+F on Windows or Command+F on Mac \n",
            "to begin a search.\n",
            " Navigating to a Topic\n",
            "View a complete list of topics in the table of contents. Click on a topic to navigate to that \n",
            "section.\n",
            " Printing this Document\n",
            "This document supports high resolution printing.This document is copyrighted by DJI with all rights reserved. Unless otherwise authorized by \n",
            "DJI, you are not eligible to use or allow others to use the document or any part of the document \n",
            "by reproducing, transferring or selling the document. Users should only refer to this document \n",
            "and the content thereof as instructions to operate DJI UAV. The document should not be used \n",
            "for other purposes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([text_gen_ai])"
      ],
      "metadata": {
        "id": "kpOIbvUOIP8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[0])\n",
        "print('-' * 100)\n",
        "print(texts[1])\n",
        "print('-' * 100)\n",
        "print(texts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CHsD2BBNTSJ",
        "outputId": "3b28a9aa-7d47-4a98-8709-d96355a1663c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='What is generative AI?\n",
            "Generative AI can learn from existing artifacts to generate new, realistic artifacts (at scale) that reflect the characteristics of the training data but don’t repeat it. It can produce a variety of novel content, such as images, video, music, speech, text, software code and product designs.  \n",
            "Generative AI uses a number of techniques that continue to evolve. Foremost are AI foundation models, which are trained on a broad set of unlabeled data that can be used for different tasks, with additional fine-tuning. Complex math and enormous computing power are required to create these trained models, but they are, in essence, prediction algorithms.'\n",
            "----------------------------------------------------------------------------------------------------\n",
            "page_content='Today, generative AI most commonly creates content in response to natural language requests — it doesn’t require knowledge of or entering code — but the enterprise use cases are numerous and include innovations in drug and chip design and material science development. (Also see “What are some practical uses of generative AI?”)'\n",
            "----------------------------------------------------------------------------------------------------\n",
            "page_content='What’s behind the sudden hype about generative AI?\n",
            "Gartner has tracked generative AI on its Hype Cycle™ for Artificial Intelligence since 2020 (also, generative AI was among our Top Strategic Technology Trends for 2022), and the technology has moved from the Innovation Trigger phase to the Peak of Inflated Expectations. But generative AI only hit mainstream headlines in late 2022 with the launch of ChatGPT, a chatbot capable of very human-seeming interactions.\n",
            "ChatGPT, launched by OpenAI, became wildly popular overnight and galvanized public attention. (OpenAI’s DALL·E 2 tool similarly generates images from text in a related generative AI innovation.)'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_list = []\n",
        "for i in range(len(texts)):\n",
        "  char_list.append(len(texts[i].page_content))\n",
        "\n",
        "print(char_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZHrQ_IXNge3",
        "outputId": "74c8c6ff-5107-4588-972c-54cbc8eb4274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[673, 328, 659, 672, 904, 989, 925, 915, 927, 936, 370, 754, 915, 984, 858, 907, 356, 995, 374, 767, 851, 878, 791, 868, 934, 777, 669]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import (RecursiveCharacterTextSplitter, Language)\n",
        "\n",
        "RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuFxcXZoNq2J",
        "outputId": "de807f73-6b21-4332-8170-dca6fd3eb52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nclass ', '\\ndef ', '\\n\\tdef ', '\\n\\n', '\\n', ' ', '']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python_code = '''\n",
        "  def hello_world():\n",
        "    print(\"Hello World\")\n",
        "\n",
        "  # Call the function\n",
        "  hello_world()\n",
        "'''"
      ],
      "metadata": {
        "id": "2b9eoguEPnAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python splitter\n",
        "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.PYTHON,\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=0,\n",
        ")\n",
        "\n",
        "python_texts = python_splitter.create_documents([python_code])"
      ],
      "metadata": {
        "id": "xjGc5GC9P7iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(python_texts))\n",
        "print(python_texts[0])\n",
        "print('-' * 100)\n",
        "print(python_texts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEWDeex3QILt",
        "outputId": "c33d5f97-7d78-4b1b-9953-7a82fbde9742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "page_content='def hello_world():\n",
            "    print(\"Hello World\")'\n",
            "----------------------------------------------------------------------------------------------------\n",
            "page_content='# Call the function\n",
            "  hello_world()'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰 단위 텍스트 분할기\n",
        "\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt3H2GAWQe7b",
        "outputId": "1a508c37-94e3-4d3f-9f8c-3125a7f31e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    return len(tokens)\n",
        "\n",
        "tiktoken_len('I love you')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFq4jT7ORjq2",
        "outputId": "f2b488e7-f639-4f86-e74a-f883a5b8e96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = tiktoken_len,\n",
        ")"
      ],
      "metadata": {
        "id": "58K6ayA-SpKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.create_documents([text_gen_ai])"
      ],
      "metadata": {
        "id": "7gj9L9CQTM3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_list = []\n",
        "for i in range(len(texts)):\n",
        "  token_list.append(tiktoken_len(texts[i].page_content))\n",
        "\n",
        "print(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBwEQwt_TZrI",
        "outputId": "e0e0ae10-671c-4df9-f873-c3a1101e3d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[639, 987, 885, 909, 658]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bJbAI-uTgst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}